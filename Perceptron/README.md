# Perceptron (퍼셉트론)
퍼셉트론은 입출력을 갖춘 알고리즘이다. 입력을 주면 정해진 규칙에 따른 값을 출력한다.
퍼셉트론에서는 ‘가중치’와 ‘편향’을 매개변수로 설정한다.
퍼셉트론으로 AND, OR 게이트 등의 논리 회로를 표현할 수 있다.
XOR 게이트는 단층 퍼셉트론으로는 표현할 수 없다.
2층 퍼셉트론을 이용하면 XOR 게이트를 표현할 수 있다.
단층 퍼셉트론은 직선형 영역만 표현할 수 있고, 다층 퍼셉트론은 비선형 영역도 표현할 수 있다.
다층 퍼셉트론은 (이론상) 컴퓨터를 표현할 수 있다.
## 개요
퍼셉트론은 신경망의 기본 구성 요소로, AND, NAND, OR 게이트를 구현할 때는 **가중치(weight)** 와 **편향(bias)** 값을 적절히 설정하여 구현한다.

---

## 1. AND Gate

### 진리표
| 입력 A | 입력 B | 출력 (A AND B) |
|:------:|:------:|:--------------:|
|   0    |   0    |       0        |
|   0    |   1    |       0        |
|   1    |   0    |       0        |
|   1    |   1    |       1        |

### 수식
$$y = \begin{cases}
0, & (w_1x_1 + w_2x_2 \leq \theta) \\
1, & (w_1x_1 + w_2x_2 > \theta)
\end{cases}$$

편향을 사용한 형태:
$$y = \begin{cases}
0, & (b + w_1x_1 + w_2x_2 \leq 0) \\
1, & (b + w_1x_1 + w_2x_2 > 0)
\end{cases}$$

여기서:
- $w_1, w_2$: 가중치 (weight)
- $b$: 편향 (bias)

### 구현 코드

**기본 구현:**
```python
def AND(x1, x2):
    w1, w2, theta = 0.5, 0.5, 0.7
    tmp = x1*w1 + x2*w2
    if tmp
```
💡 **Note:** NAND는 AND와 가중치(w)와 편향(b)의 부호만 다르다.

---

## 3. OR Gate

### 진리표
| 입력 A | 입력 B | 출력 (A OR B) |
|:------:|:------:|:-------------:|
|   0    |   0    |       0       |
|   0    |   1    |       1       |
|   1    |   0    |       1       |
|   1    |   1    |       1       |

### 구현 코드
```python
import numpy as np

def OR(x1, x2):
    x = np.array([x1, x2])
    w = np.array([0.5, 0.5])  # 가중치
    b = -0.2  # 편향
    tmp = np.sum(w*x) + b
    if tmp 
```    
 **핵심:** 비선형 문제는 다층 퍼셉트론을 통해 해결할 수 있으며, 이것이 딥러닝의 기본 원리다.

 # XOR Perceptron (배타적 논리합 퍼셉트론)

## 1. XOR 게이트란?

XOR(Exclusive OR, 배타적 논리합)는 두 입력이 **서로 다를 때만** 1을 출력하는 논리 게이트이다.

### 진리표
| 입력 A | 입력 B | 출력 (A XOR B) |
|:------:|:------:|:--------------:|
|   0    |   0    |       0        |
|   0    |   1    |       1        |
|   1    |   0    |       1        |
|   1    |   1    |       0        |

---

## 2. 단층 퍼셉트론의 한계

### 🚫 선형 분리 불가능

XOR 문제는 **단층 퍼셉트론으로 해결할 수 없다**. 그 이유는 XOR의 출력을 **하나의 직선으로 분리할 수 없기** 때문이다.

### 시각적 이해

2차원 평면에 XOR의 입력과 출력을 표시하면:

```
  x2
  ^
1 | ● (1,1) → 0
  | 
  | ○ (0,1) → 1
  |_________> x1
0   ○ (1,0) → 1
    ● (0,0) → 0
```

- ○: 출력 1
- ●: 출력 0

**하나의 직선으로는 ○와 ●를 분리할 수 없다!**

### 수학적 증명

단층 퍼셉트론의 출력:
$$y = \begin{cases}
1, & (w_1x_1 + w_2x_2 + b > 0) \\
0, & (w_1x_1 + w_2x_2 + b \leq 0)
\end{cases}$$

XOR의 조건을 만족하려면:
- $(0,0)$: $b \leq 0$ ... ①
- $(0,1)$: $w_2 + b > 0$ ... ②
- $(1,0)$: $w_1 + b > 0$ ... ③
- $(1,1)$: $w_1 + w_2 + b \leq 0$ ... ④

②와 ③을 더하면: $w_1 + w_2 + 2b > 0$  
그런데 ①에서 $b \leq 0$이므로, ④의 $w_1 + w_2 + b \leq 0$과 **모순**이 발생한다다!

---

## 3. 해결책: 다층 퍼셉트론 (Multi-Layer Perceptron)

### 기본 아이디어

XOR를 기존의 논리 게이트들의 조합으로 표현할 수 있음:

**XOR = (A NAND B) AND (A OR B)**

### 논리 구조

```
입력층        은닉층         출력층
  x1 ──┐
       ├──→ NAND ──┐
  x2 ──┤           ├──→ AND ──→ y
       └──→ OR  ──┘
```

### 수식 표현

- $s_1 = x_1 \; \text{NAND} \; x_2$
- $s_2 = x_1 \; \text{OR} \; x_2$
- $y = s_1 \; \text{AND} \; s_2$

---

## 4. 구현

### 필요한 게이트 함수들

```python
import numpy as np

def AND(x1, x2):
    x = np.array([x1, x2])
    w = np.array([0.5, 0.5])
    b = -0.7
    tmp = np.sum(w*x) + b
    if tmp  0).astype(int)            # 활성화 함수 (계단 함수)
    
    # 출력층
    W2 = np.array([0.5, 0.5])     # AND의 가중치
    B2 = -0.7                      # AND의 편향
    
    y = np.sum(W2 * h) + B2
    y = 1 if y > 0 else 0          # 활성화 함수
    
    return y
```

---

## 7. 핵심 정리

### XOR 문제의 중요성

| 항목 | 내용 |
|:----:|:-----|
| **역사적 의미** | 1969년 민스키와 페퍼트가 단층 퍼셉트론의 한계를 지적하며 첫 번째 AI 겨울을 초래 |
| **이론적 의미** | 비선형 문제는 다층 구조가 필요함을 증명 |
| **실용적 의미** | 딥러닝의 필요성을 보여주는 가장 간단한 예제 |

### 학습 포인트

✅ **단층 퍼셉트론**: 선형 분리 가능한 문제만 해결 (AND, OR, NAND)  
✅ **다층 퍼셉트론**: 비선형 문제 해결 가능 (XOR)  
✅ **은닉층의 역할**: 입력 공간을 변환하여 선형 분리 가능하게 만듦  
✅ **층을 쌓는 이유**: 더 복잡한 함수를 표현하기 위해

### 일반화

XOR 문제 해결은 다음을 의미함:
- 2층 신경망으로 **임의의 논리 함수** 표현 가능
- 충분한 층과 뉴런으로 **임의의 연속 함수** 근사 가능 (보편 근사 정리)
- **딥러닝의 이론적 기반** 제공

---

## 8. 참고: 시각화

### 결정 경계 변화

**단층 퍼셉트론 (불가능):**
```
x2 |
 1 | ● ○    하나의 직선으로
   | ○ ●    분리 불가능
 0 |_____x1
   0     1
```

**다층 퍼셉트론 (가능):**
```
은닉층에서 변환된 공간:
s2 |
 1 | ○ ●    선형 분리
   | ○ ●    가능!
 0 |_____s1
   0     1
```

이것이 바로 **표현 학습(Representation Learning)** 의 핵심!