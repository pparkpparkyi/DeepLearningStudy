# Perceptron (퍼셉트론)
퍼셉트론은 입출력을 갖춘 알고리즘이다. 입력을 주면 정해진 규칙에 따른 값을 출력한다.
퍼셉트론에서는 ‘가중치’와 ‘편향’을 매개변수로 설정한다.
퍼셉트론으로 AND, OR 게이트 등의 논리 회로를 표현할 수 있다.
XOR 게이트는 단층 퍼셉트론으로는 표현할 수 없다.
2층 퍼셉트론을 이용하면 XOR 게이트를 표현할 수 있다.
단층 퍼셉트론은 직선형 영역만 표현할 수 있고, 다층 퍼셉트론은 비선형 영역도 표현할 수 있다.
다층 퍼셉트론은 (이론상) 컴퓨터를 표현할 수 있다.
## 개요
퍼셉트론은 신경망의 기본 구성 요소로, AND, NAND, OR 게이트를 구현할 때는 **가중치(weight)** 와 **편향(bias)** 값을 적절히 설정하여 구현한다.

---

## 1. AND Gate

### 진리표
| 입력 A | 입력 B | 출력 (A AND B) |
|:------:|:------:|:--------------:|
|   0    |   0    |       0        |
|   0    |   1    |       0        |
|   1    |   0    |       0        |
|   1    |   1    |       1        |

### 수식
$$y = \begin{cases}
0, & (w_1x_1 + w_2x_2 \leq \theta) \\
1, & (w_1x_1 + w_2x_2 > \theta)
\end{cases}$$

편향을 사용한 형태:
$$y = \begin{cases}
0, & (b + w_1x_1 + w_2x_2 \leq 0) \\
1, & (b + w_1x_1 + w_2x_2 > 0)
\end{cases}$$

여기서:
- $w_1, w_2$: 가중치 (weight)
- $b$: 편향 (bias)

### 구현 코드

**기본 구현:**
```python
def AND(x1, x2):
    w1, w2, theta = 0.5, 0.5, 0.7
    tmp = x1*w1 + x2*w2
    if tmp
```
💡 **Note:** NAND는 AND와 가중치(w)와 편향(b)의 부호만 다르다.

---

## 3. OR Gate

### 진리표
| 입력 A | 입력 B | 출력 (A OR B) |
|:------:|:------:|:-------------:|
|   0    |   0    |       0       |
|   0    |   1    |       1       |
|   1    |   0    |       1       |
|   1    |   1    |       1       |

### 구현 코드
```python
import numpy as np

def OR(x1, x2):
    x = np.array([x1, x2])
    w = np.array([0.5, 0.5])  # 가중치
    b = -0.2  # 편향
    tmp = np.sum(w*x) + b
    if tmp 
```    
 **핵심:** 비선형 문제는 다층 퍼셉트론을 통해 해결할 수 있으며, 이것이 딥러닝의 기본 원리다.

 # XOR Perceptron (배타적 논리합 퍼셉트론)

## 1. XOR 게이트란?

XOR(Exclusive OR, 배타적 논리합)는 두 입력이 **서로 다를 때만** 1을 출력하는 논리 게이트이다.

### 진리표
| 입력 A | 입력 B | 출력 (A XOR B) |
|:------:|:------:|:--------------:|
|   0    |   0    |       0        |
|   0    |   1    |       1        |
|   1    |   0    |       1        |
|   1    |   1    |       0        |

---

## 2. 단층 퍼셉트론의 한계

### 🚫 선형 분리 불가능

XOR 문제는 **단층 퍼셉트론으로 해결할 수 없다**. 그 이유는 XOR의 출력을 **하나의 직선으로 분리할 수 없기** 때문이다.

### 시각적 이해

2차원 평면에 XOR의 입력과 출력을 표시하면:

```
  x2
  ^
1 | ● (1,1) → 0
  | 
  | ○ (0,1) → 1
  |_________> x1
0   ○ (1,0) → 1
    ● (0,0) → 0
```

- ○: 출력 1
- ●: 출력 0

**하나의 직선으로는 ○와 ●를 분리할 수 없다!**

### 수학적 증명

단층 퍼셉트론의 출력:
$$y = \begin{cases}
1, & (w_1x_1 + w_2x_2 + b > 0) \\
0, & (w_1x_1 + w_2x_2 + b \leq 0)
\end{cases}$$

XOR의 조건을 만족하려면:
- $(0,0)$: $b \leq 0$ ... ①
- $(0,1)$: $w_2 + b > 0$ ... ②
- $(1,0)$: $w_1 + b > 0$ ... ③
- $(1,1)$: $w_1 + w_2 + b \leq 0$ ... ④

②와 ③을 더하면: $w_1 + w_2 + 2b > 0$  
그런데 ①에서 $b \leq 0$이므로, ④의 $w_1 + w_2 + b \leq 0$과 **모순**이 발생한다다!

---

## 3. 해결책: 다층 퍼셉트론 (Multi-Layer Perceptron)

### 기본 아이디어

XOR를 기존의 논리 게이트들의 조합으로 표현할 수 있음:

**XOR = (A NAND B) AND (A OR B)**

### 논리 구조

```
입력층        은닉층         출력층
  x1 ──┐
       ├──→ NAND ──┐
  x2 ──┤           ├──→ AND ──→ y
       └──→ OR  ──┘
```

### 수식 표현

- $s_1 = x_1 \; \text{NAND} \; x_2$
- $s_2 = x_1 \; \text{OR} \; x_2$
- $y = s_1 \; \text{AND} \; s_2$

---

## 4. 구현

### 필요한 게이트 함수들

```python
import numpy as np

def AND(x1, x2):
    x = np.array([x1, x2])
    w = np.array([0.5, 0.5])
    b = -0.7
    tmp = np.sum(w*x) + b
    if tmp  0).astype(int)            # 활성화 함수 (계단 함수)
    
    # 출력층
    W2 = np.array([0.5, 0.5])     # AND의 가중치
    B2 = -0.7                      # AND의 편향
    
    y = np.sum(W2 * h) + B2
    y = 1 if y > 0 else 0          # 활성화 함수
    
    return y
```

---

## 7. 핵심 정리

### XOR 문제의 중요성

| 항목 | 내용 |
|:----:|:-----|
| **역사적 의미** | 1969년 민스키와 페퍼트가 단층 퍼셉트론의 한계를 지적하며 첫 번째 AI 겨울을 초래 |
| **이론적 의미** | 비선형 문제는 다층 구조가 필요함을 증명 |
| **실용적 의미** | 딥러닝의 필요성을 보여주는 가장 간단한 예제 |

### 학습 포인트

✅ **단층 퍼셉트론**: 선형 분리 가능한 문제만 해결 (AND, OR, NAND)  
✅ **다층 퍼셉트론**: 비선형 문제 해결 가능 (XOR)  
✅ **은닉층의 역할**: 입력 공간을 변환하여 선형 분리 가능하게 만듦  
✅ **층을 쌓는 이유**: 더 복잡한 함수를 표현하기 위해

### 일반화

XOR 문제 해결은 다음을 의미함:
- 2층 신경망으로 **임의의 논리 함수** 표현 가능
- 충분한 층과 뉴런으로 **임의의 연속 함수** 근사 가능 (보편 근사 정리)
- **딥러닝의 이론적 기반** 제공

---

## 8. 참고: 시각화

### 결정 경계 변화

**단층 퍼셉트론 (불가능):**
```
x2 |
 1 | ● ○    하나의 직선으로
   | ○ ●    분리 불가능
 0 |_____x1
   0     1
```

**다층 퍼셉트론 (가능):**
```
은닉층에서 변환된 공간:
s2 |
 1 | ○ ●    선형 분리
   | ○ ●    가능!
 0 |_____s1
   0     1
```

이것이 바로 **표현 학습(Representation Learning)** 의 핵심!

# 2장 퍼셉트론 - 시험 대비 핵심 정리

## 1. 퍼셉트론의 기본 개념

### 퍼셉트론이란?

**다수의 신호를 입력받아 하나의 신호를 출력하는 알고리즘**

```python
# 기본 구조
"""
입력: x1, x2
가중치: w1, w2
편향: b
출력: y

y = 0 (w1*x1 + w2*x2 + b ≤ 0)
y = 1 (w1*x1 + w2*x2 + b > 0)
"""
```

### 수식

$$y = \begin{cases}
0, & (b + w_1x_1 + w_2x_2 \leq 0) \\
1, & (b + w_1x_1 + w_2x_2 > 0)
\end{cases}$$

또는

$$y = \begin{cases}
0, & (w_1x_1 + w_2x_2 \leq \theta) \\
1, & (w_1x_1 + w_2x_2 > \theta)
\end{cases}$$

- $w$: 가중치 (weight) - 신호의 중요도
- $b$: 편향 (bias) - 뉴런의 활성화 난이도
- $\theta$: 임계값 (threshold)

---

## 2. 논리 게이트 구현 ⭐⭐⭐

### AND 게이트

**진리표:**
| x1 | x2 | y |
|:--:|:--:|:-:|
| 0  | 0  | 0 |
| 0  | 1  | 0 |
| 1  | 0  | 0 |
| 1  | 1  | 1 |

**구현:**
```python
import numpy as np

def AND(x1, x2):
    x = np.array([x1, x2])
    w = np.array([0.5, 0.5])
    b = -0.7
    tmp = np.sum(w*x) + b
    if tmp  x1
0   ○ (1,0) → 1
    ● (0,0) → 0

○: 출력 1
●: 출력 0

하나의 직선으로 ○와 ●를 분리할 수 없음!
"""
```

### 선형과 비선형

**선형 함수:**
```python
# 예: f(x) = ax + b
# 층을 아무리 깊게 해도 결국 선형 함수

# 3층
h(h(h(x))) = c*c*c*x = c³x  # 여전히 선형!

# 따라서 선형 함수는 층을 쌓는 의미가 없음
```

**비선형 함수:**
```python
# 퍼셉트론의 활성화 함수 (계단 함수)는 비선형
# 신경망에서는 시그모이드, ReLU 등 비선형 함수 사용
```

---

## 4. 다층 퍼셉트론 (Multi-Layer Perceptron) ⭐⭐⭐

### XOR 문제 해결

**핵심 아이디어:** 기존 게이트를 조합

$$\text{XOR} = (x_1 \text{ NAND } x_2) \text{ AND } (x_1 \text{ OR } x_2)$$

**구조:**
```
     입력층        은닉층         출력층
      x1 ──┐
           ├──→ NAND ──┐
      x2 ──┤           ├──→ AND ──→ y
           └──→ OR  ──┘
```

### 구현

```python
def XOR(x1, x2):
    s1 = NAND(x1, x2)  # 은닉층 뉴런 1
    s2 = OR(x1, x2)    # 은닉층 뉴런 2
    y = AND(s1, s2)    # 출력층
    return y

# 테스트
print(XOR(0, 0))  # 0
print(XOR(0, 1))  # 1
print(XOR(1, 0))  # 1
print(XOR(1, 1))  # 0
```

### 중간 계층 동작

| x1 | x2 | s1 (NAND) | s2 (OR) | y (AND) |
|:--:|:--:|:---------:|:-------:|:-------:|
| 0  | 0  |     1     |    0    |    0    |
| 0  | 1  |     1     |    1    |    1    |
| 1  | 0  |     1     |    1    |    1    |
| 1  | 1  |     0     |    1    |    0    |

**핵심:** 은닉층에서 **표현을 변환**하여 선형 분리 가능하게 만듦

---

## 5. 가중치와 편향의 의미 ⭐⭐

### 가중치 (Weight)

```python
# 가중치가 클수록 해당 입력의 중요도가 높음

# 예: w1 = 1.0, w2 = 0.1
# → x1이 x2보다 10배 중요
```

### 편향 (Bias)

```python
# 편향은 뉴런의 활성화 난이도를 조절

# b가 크면 → 활성화되기 쉬움 (임계값이 낮음)
# b가 작으면 → 활성화되기 어려움 (임계값이 높음)

# 예:
# b = -0.2 (OR)  → 쉽게 활성화
# b = -0.7 (AND) → 어렵게 활성화
```

---

## 6. 시험 필수 개념 정리

### ✅ 반드시 알아야 할 것

1. **퍼셉트론 수식**
   $$y = \begin{cases}
   0, & (b + w_1x_1 + w_2x_2 \leq 0) \\
   1, & (b + w_1x_1 + w_2x_2 > 0)
   \end{cases}$$

2. **논리 게이트 구현**
   - AND, NAND, OR의 가중치와 편향 값
   - 각 게이트의 진리표

3. **단층 퍼셉트론의 한계**
   - 선형 분리 가능한 문제만 해결
   - XOR은 비선형 문제 → 불가능

4. **다층 퍼셉트론**
   - XOR을 NAND, OR, AND 조합으로 구현
   - 층을 쌓으면 비선형 문제 해결 가능

5. **선형 vs 비선형**
   - 신경망은 반드시 비선형 활성화 함수 사용
   - 선형 함수는 층을 쌓아도 의미 없음

---

## 7. 시험 예상 문제

### 문제 1 (10점)
```
다음 퍼셉트론의 출력을 구하시오.

w1 = 0.5, w2 = 0.5, b = -0.3

(1) x1 = 0, x2 = 0
(2) x1 = 0, x2 = 1
(3) x1 = 1, x2 = 0
(4) x1 = 1, x2 = 1
```

**답안:**
```python
# (1) 0.5*0 + 0.5*0 + (-0.3) = -0.3 ≤ 0 → y = 0
# (2) 0.5*0 + 0.5*1 + (-0.3) = 0.2 > 0  → y = 1
# (3) 0.5*1 + 0.5*0 + (-0.3) = 0.2 > 0  → y = 1
# (4) 0.5*1 + 0.5*1 + (-0.3) = 0.7 > 0  → y = 1

답: (1) 0, (2) 1, (3) 1, (4) 1 → OR 게이트
```

---

### 문제 2 (10점)
```
AND 게이트를 구현하는 퍼셉트론의 가중치와 편향을 
하나의 예시로 제시하시오.
```

**답안:**
```python
w1 = 0.5
w2 = 0.5
b = -0.7

# 또는
w1 = 1.0
w2 = 1.0
b = -1.5

# (정답은 여러 개 가능, 조건만 만족하면 됨)
```

---

### 문제 3 (10점)
```
단층 퍼셉트론으로 XOR 게이트를 구현할 수 없는 이유를 
설명하시오.
```

**답안:**
```
XOR 게이트는 선형 분리가 불가능한 비선형 문제이기 때문이다.
단층 퍼셉트론은 하나의 직선(또는 초평면)으로 출력 0과 1을 
구분하는데, XOR의 경우 출력 0인 점들과 출력 1인 점들을 
하나의 직선으로 분리할 수 없다.

따라서 XOR을 구현하려면 다층 퍼셉트론이 필요하다.
```

---

### 문제 4 (15점)
```
XOR 게이트를 다층 퍼셉트론으로 구현하는 방법을 
그림과 함께 설명하시오.
```

**답안:**
```python
# 그림
"""
     x1 ──┐
          ├──→ NAND (s1) ──┐
     x2 ──┤                ├──→ AND (y)
          └──→ OR (s2) ───┘
"""

# 설명
XOR = (x1 NAND x2) AND (x1 OR x2)

# 중간 계층 진리표
| x1 | x2 | s1(NAND) | s2(OR) | y(AND) |
|----|----| ---------|--------|--------|
| 0  | 0  |    1     |   0    |   0    |
| 0  | 1  |    1     |   1    |   1    |
| 1  | 0  |    1     |   1    |   1    |
| 1  | 1  |    0     |   1    |   0    |

# 코드
def XOR(x1, x2):
    s1 = NAND(x1, x2)
    s2 = OR(x1, x2)
    y = AND(s1, s2)
    return y
```

---

### 문제 5 (10점)
```
신경망에서 선형 함수를 활성화 함수로 사용하면 안 되는 
이유를 설명하시오.
```

**답안:**
```
선형 함수를 활성화 함수로 사용하면 층을 아무리 깊게 쌓아도
결국 하나의 선형 함수로 표현되기 때문이다.

예: h(x) = cx를 사용하면
3층: h(h(h(x))) = c*c*c*x = c³x (여전히 선형)

따라서 층을 쌓는 의미가 없어지고, 복잡한 비선형 문제를 
해결할 수 없다. 신경망의 표현력을 높이기 위해서는 
시그모이드, ReLU 같은 비선형 활성화 함수가 필요하다.
```

---

## 8. 핵심 암기 사항

### 논리 게이트 파라미터 (암기!)

```python
# AND
w1 = 0.5, w2 = 0.5, b = -0.7

# NAND
w1 = -0.5, w2 = -0.5, b = 0.7

# OR
w1 = 0.5, w2 = 0.5, b = -0.2
```

### 중요 개념 (반드시!)

1. **퍼셉트론 = 가중치 × 입력 + 편향**
2. **단층 퍼셉트론 = 선형 분리만 가능**
3. **XOR = 비선형 문제 = 단층으로 불가능**
4. **다층 퍼셉트론 = 비선형 문제 해결 가능**
5. **활성화 함수는 반드시 비선형**

---

## 9. 빠른 복습 체크리스트

- [ ] 퍼셉트론의 수식 이해
- [ ] AND, NAND, OR 구현 가능
- [ ] 각 게이트의 진리표 암기
- [ ] 가중치와 편향의 역할 설명 가능
- [ ] 단층 퍼셉트론의 한계 설명 가능
- [ ] XOR이 왜 안 되는지 설명 가능
- [ ] XOR을 다층으로 구현하는 방법
- [ ] 선형 vs 비선형 차이 이해
- [ ] 왜 비선형 함수가 필요한지 설명 가능

---

## 10. 마무리 핵심 정리

### 퍼셉트론의 핵심 3가지

```python
"""
1. 구조
   입력 → 가중치 곱 → 합산 + 편향 → 활성화 함수 → 출력

2. 한계
   선형 분리 가능한 문제만 해결 (AND, OR, NAND ○, XOR ×)

3. 해결
   층을 쌓으면 비선형 문제 해결 가능 (다층 퍼셉트론)
"""
```

### 역사적 의미

```
1957년: 퍼셉트론 발명 (Rosenblatt)
1969년: 퍼셉트론의 한계 지적 (Minsky & Papert)
       → 첫 번째 AI 겨울
1980년대: 다층 퍼셉트론 + 역전파 알고리즘
       → 신경망 부활
```

**시험 화이팅! 🎯**